package cn.ffcs.is.mss.analyzer.flink.streaming

import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment
import org.apache.flink.streaming.api.scala._
import org.apache.flink.streaming.connectors.redis.RedisSink
import org.apache.flink.streaming.connectors.redis.common.config.FlinkJedisPoolConfig
import org.apache.flink.streaming.connectors.redis.common.mapper.{RedisCommand, RedisCommandDescription, RedisMapper}

/**
 * @ClassName:
 * @Author: mengwenting
 * @Date: 2023/8/2 18:17
 * @Description:
 * @update:
 */
object Demo_RedisSink{
  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment

    val ds = env.socketTextStream("192.168.1.23", 8888)
      .map(x => {
        val fields = x.split("\\|")
        val date = fields(0).trim
        val province = fields(1).trim
        val add = fields(2).trim.toInt
        val possible = fields(3).trim.toInt
        //封装二元组返回
        (date + "_" + province, (add, possible))
      })
      .keyBy(0)
      .reduce((kv1, kv2) => (kv1._1, (kv1._2._1 + kv2._2._1, kv1._2._2 + kv2._2._2)))
      .map(y => {
        //封装并返回
        (y._1, y._2._1 + "_" + y._2._2)
      })

    val config = new FlinkJedisPoolConfig.Builder()
      .setHost("192.168.1.22")
      .setPassword("root")
      .setPort(6379)
      .setDatabase(2)
      .build()

    //将RedisSink实例绑定到数据流中
    ds.addSink(new RedisSink[(String, String)](config, new MyRedisMapper))


    env.execute("Redis Sink")
  }
}

//自定义RedisMapper
class MyRedisMapper extends RedisMapper[(String, String)]{
  //获取命令
  override def getCommandDescription: RedisCommandDescription = new RedisCommandDescription(RedisCommand.SET)
  //从数据中获取key
  override def getKeyFromData(data: (String, String)): String = data._1
  //从数据中获取value
  override def getValueFromData(data: (String, String)): String = data._2
}
